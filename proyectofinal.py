# -*- coding: utf-8 -*-
"""ProyectoFinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GgxOsjIiRC7VANBdYQnKvIjQzlwE0AFH

# Proyecto Final Introducción a la Ciencia de Datos con Python
# Martínez Pardo Esaú

## Identificar la relación entre las horas de estudio y las calificaciones.
"""

!pip install seaborn

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import numpy as np

# Carga el dataset proporcionado.
df = pd.read_csv('/content/Esaú Martínez Pardo - linear_regression_data.csv')
df

# Intercambio el nombre de las columnas
df.columns = ['Calificación', 'Horas de Estudio']
df

# Realiza un gráfico de dispersión entre las columnas Horas de Estudio y Calificación.
sns.scatterplot(data =  df, x = 'Horas de Estudio', y = 'Calificación')

# Haz un análisis de correlación entre las variables por medio de heatmaps o pairplots.
df['Calificación'].corr(df['Horas de Estudio'])

plt.figure(figsize=(10,6))
sns.heatmap(df.corr(), annot=True, linewidths=.5,cmap='viridis')

# Ajusta una línea de regresión y visualízala sobre el gráfico.
sns.scatterplot(df)

lr = LinearRegression()
# Definimos las variables independiente (X) y dependiente (y)
i_x = df['Horas de Estudio']
d_y = df['Calificación']
lr.fit(i_x.to_frame(), d_y)

"""Hasta este punto ya se encontró la mejor recta. "Tenemos el mejor valor para 'm' y para 'b'"""

# Usando nuestro modelo entrenado, usamos de nuevo nuestra variable x para intentar predecir y
y_predict = lr.predict(i_x.to_frame())

# Datos originales (azul)
sns.scatterplot(x = i_x, y = d_y, s=40);
# Datos mejorados (naranja)
sns.scatterplot(x = i_x, y = y_predict, s=25);

# Calcular distancia entre puntos naranjas y azules
sns.scatterplot(x = i_x, y = d_y, s=40);
sns.scatterplot(x = i_x, y = y_predict, s=25);

for i in range(len(i_x)):
    plt.plot([i_x[i], i_x[i]], [d_y[i], y_predict[i]], 'g--')

# Formamos la línea con los puntos naranja
sns.scatterplot(x = i_x, y = d_y, s=40);
sns.lineplot(x = i_x, y = y_predict, color='#FF7F0E');

# Extraemos la ecuación de la recta
intercept = lr.intercept_ #b
coefficient = lr.coef_[0] #m

# Ecuación que calcula el modelo de machine learning
print(f'y = {coefficient} * x + {intercept}')

# Comprobamos resultados
print(f'Valor de x: {i_x[10]}')
print(f'Valor predecido por nuestro modelo: {y_predict[10]}') # modelo machine learning
print(f'Valor cuantificado directamente usando la funcion: {coefficient * i_x[10] + intercept}') # ecuación

# Revisa la R^2 del resultado y explica.
# Analizar el resultado original con el de machine learning y que me diga que tan correlaciones están los valores
# que esperaba con los que obtuve
# Método a mano
print(f'R2: {np.power(i_x.corr(d_y), 2)}')

# Calculo usando el método scrore de machine learning
print(f'R2: {lr.score(i_x.to_frame(), d_y)}')

"""Responde: ¿Existe una relación positiva entre las horas de estudio y las calificaciones?

Sí, mientras más estudies, obtienes una mayor calificación. Eso lo podemos ver en la gráfica anterior, en donde se pinta una pendiente positiva. En la gráfica de dispersión, los puntos tienden a alinearse en una dirección ascendente. La pendiente positiva de la línea de regresión nos dice que a medida que aumentan las horas de estudio, también tienden a incrementarse las calificaciones.

## Agrupar clientes en función de sus ingresos mensuales y su gasto anual.
"""

# Carga el dataset proporcionado.
d_f = pd.read_csv('/content/Esaú Martínez Pardo - kmeans_data.csv')
d_f

# Realiza un gráfico de dispersión entre las columnas Ingresos Mensuales y Gasto Anual.
sns.pairplot(d_f)

# CORREGIDO EL PASO ANTERIOR
sns.scatterplot(data =  d_f, x = 'Ingresos Mensuales', y = 'Gasto Anual')

from sklearn.cluster import KMeans

# Aplica el algoritmo K-Means con k=3.
# Agrupamos en 3 clusters
k_means = KMeans(n_clusters=3, max_iter=10000)

# Entrenamos el algoritmo
k_means.fit(d_f[['Ingresos Mensuales', 'Gasto Anual']])

# Localizamos la ubicación de los 3 puntos
centers = k_means.cluster_centers_

centers

# Grafica los datos agrupados según los clusters generados.

# Clasificamos los datos para que se vean más claros los grupos
clasificaciones = k_means.predict(d_f[['Ingresos Mensuales', 'Gasto Anual']])

# Graficamos coloreando cada grupo de un distinto color
fig = plt.figure()
ax = fig.add_subplot()

ax.set_title('APLICACIÓN K-MEANS', pad=15)
ax.set_xlabel('Ingresos Mensuales')
ax.set_ylabel('Gasto Anual')

sns.scatterplot(x = d_f['Ingresos Mensuales'], y = d_f['Gasto Anual'], ax=ax, hue=clasificaciones, palette='rainbow');
sns.scatterplot(x = centers[:,0], y = centers[:,1], ax=ax, s=100, color='black');

ax.get_legend().remove()

"""Responde: ¿Qué características comunes tienen los clientes en cada grupo?

Las personas con menores ingresos mensuales, tienden a gastar menos, es decir, es proporcional su ingreso con su gasto: reciben menos ingresos-gastan menos / reciben más ingresos - gastan más.
Por ejemplo, el grupo 'verde' tiene de 2000 a 4000 de ingresos mensuales, por lo que suelen gastar menos de 20000 anualmente. La pendiente sube con los de ingresos de 6000 a 8000 mensuales, gastan más los 'rojos' que los 'verdes' (de 25000 a 30000). Finalmente vemos al cluster 'morado' en la esquina superior derecha de la gráfica, como reciben más ingresos que los demás grupos (11000 a 14000), gastan más dinero, de 40000 a más de 50000, pues suponemos que tienden a tener un estilo de vida más elevado.
"""